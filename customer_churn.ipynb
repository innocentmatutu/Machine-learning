{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJIJXUEydFNTOR6muPlh4V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/innocentmatutu/Machine-learning/blob/main/customer_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU26I_tJFTKx",
        "outputId": "c65ca990-a50d-4569-fa57-431f7e9769e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.7963094393186657\n",
            "Recall Score: 0.7963094393186657\n",
            "Precision Score: 0.7961131933810797\n",
            "F1_score: 0.7962108716881399\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "\n",
        "df=pd.read_csv('/content/archive (5).zip')\n",
        "\n",
        "features=['tenure','MonthlyCharges','TotalCharges','SeniorCitizen','Partner','Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaperlessBilling','PaymentMethod']\n",
        "X=df[features]\n",
        "y=df['Churn']\n",
        "df.drop(['Churn'],axis=1,inplace=True)\n",
        "\n",
        "#Encode the target variable\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "#Break of validation set from training set\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "#Select categorical columns with relatively low cardinality\n",
        "categorical_cols = [cname for cname in X_train.columns if\n",
        "                    X_train[cname].nunique()<10 and\n",
        "                    X_train[cname].dtype=='object']\n",
        "\n",
        "#select numerical columns\n",
        "numerical_cols = [cname for cname in X_train.columns if\n",
        "                  X_train[cname].dtype in ['int64','float64']]\n",
        "\n",
        "#keep selected columns\n",
        "my_cols = categorical_cols + numerical_cols\n",
        "X_train = X_train[my_cols].copy()\n",
        "X_valid = X_valid[my_cols].copy()\n",
        "\n",
        "#preprocessing of numerical data\n",
        "numerical_transformer = SimpleImputer(strategy='constant')\n",
        "\n",
        "#preprocessing of categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "          ('imputer',SimpleImputer(strategy='most_frequent')),\n",
        "          ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "#Bundle preprocessing for numerical data and categorical data\n",
        "preprocesser = ColumnTransformer(\n",
        "        transformers = [\n",
        "            ('num',numerical_transformer,numerical_cols),\n",
        "            ('cat',categorical_transformer,categorical_cols)\n",
        "        ]\n",
        ")\n",
        "\n",
        "#modle selection\n",
        "#model = LogisticRegression(max_iter=1000, solver='lbfgs',random_state=1)\n",
        "model = xgb.XGBClassifier(random_state=1)\n",
        "\n",
        "#Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor',preprocesser),\n",
        "    ('model',model)\n",
        "\n",
        "])\n",
        "\n",
        "#model fit\n",
        "my_pipeline.fit(X_train,y_train)\n",
        "\n",
        "#model predictions\n",
        "preds= my_pipeline.predict(X_valid)\n",
        "\n",
        "#model evaluation\n",
        "print(f'Accuracy Score: {accuracy_score(y_valid,preds)}')\n",
        "print(f'Recall Score: {recall_score(y_valid,preds,average=\"weighted\")}')\n",
        "print(f'Precision Score: {precision_score(y_valid, preds, average=\"weighted\")}')\n",
        "print(f'F1_score: {f1_score(y_valid, preds, average=\"weighted\")}')\n",
        "\n",
        "\n",
        "#print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
        "\n",
        "\n",
        "df=pd.read_csv('/content/archive (5).zip')\n",
        "\n",
        "features=['tenure','MonthlyCharges','TotalCharges','SeniorCitizen','Partner','Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','Contract','PaperlessBilling','PaymentMethod']\n",
        "X=df[features]\n",
        "y=df['Churn']\n",
        "df.drop(['Churn'], axis=1 ,inplace=True)\n",
        "\n",
        "#Encode the target column\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "#Split training and testing data\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "#Select categorical columns with relatively low cardinality\n",
        "categorical_cols = [cname for cname in X_train.columns if\n",
        "                    X_train[cname].nunique()<10 and\n",
        "                    X_train[cname].dtype=='object']\n",
        "\n",
        "#Select numerical columns\n",
        "numerical_cols = [cname for cname in X_train.columns if\n",
        "                  X_train[cname].dtype in ['float64','int64']]\n",
        "\n",
        "#Put together the selected columns\n",
        "my_cols = categorical_cols + numerical_cols\n",
        "X_train = X_train[my_cols].copy()\n",
        "X_valid = X_valid[my_cols].copy()\n",
        "\n",
        "#Preprocess numerical columns\n",
        "numerical_transformer = SimpleImputer(strategy='constant')\n",
        "\n",
        "#Preprocess categorical columns\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('impute',SimpleImputer(strategy='most_frequent')),\n",
        "    ('ohe',OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "#Bundle preprocessing of numerical and categorical columns into a pipeline\n",
        "preprocesser = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num',numerical_transformer,numerical_cols),\n",
        "        ('cat',categorical_transformer,categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "#Model selection\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "#Bundle preprocessing and model code into pipeline\n",
        "my_pipeline = Pipeline(steps=[\n",
        "    ('preprocesser',preprocesser),\n",
        "    ('model',model)\n",
        "])\n",
        "\n",
        "#Model fit\n",
        "my_pipeline.fit(X_train,y_train)\n",
        "\n",
        "#Model predictions\n",
        "preds = my_pipeline.predict(X_valid)\n",
        "\n",
        "#Model evalutions\n",
        "print(f'Accuracy score: {accuracy_score(y_valid,preds)}')\n",
        "print(f'Precision score: {precision_score(y_valid,preds,average=\"weighted\")}')\n",
        "print(f'F1 score: {f1_score(y_valid,preds,average=\"weighted\")}')\n",
        "print(f'Recall score: {recall_score(y_valid,preds,average=\"weighted\")}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRYfjV_vaytF",
        "outputId": "e31d956b-e0a7-4d3e-80fa-e389ceba12ff"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.7650816181689141\n",
            "Precision score: 0.7590034934041696\n",
            "F1 score: 0.7616399995734032\n",
            "Recall score: 0.7650816181689141\n"
          ]
        }
      ]
    }
  ]
}