{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpKFkxK9GPAfyV7fPf+Ji6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/innocentmatutu/Machine-learning/blob/main/Imputation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSBWFD6vQLGz",
        "outputId": "5d6d3e12-56a4-4fe2-9a87-48a7a30a4bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3102890118.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(),inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.7012987012987013\n",
            "Precison score: 0.6176194618778351\n",
            "Recall score: 0.7012987012987013\n",
            "F1 score: 0.6456899475332655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "with zipfile.ZipFile('/content/archive (4).zip') as z:\n",
        "  with z.open('weather_dirty.csv') as f:\n",
        "    df = pd.read_csv(f , sep=';')\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'],format='mixed')\n",
        "df = df.dropna(axis=1, how='all')\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "numeric_cols = ['Temperature_day', 'Temperature_night', 'AirPressure_hPa',\n",
        "                'WindSpeed_km/h', 'Precipitation_mm']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "for col in df.select_dtypes(include=['number']).columns:\n",
        "  #df[col].dropna(inplace=True)\n",
        "  #df[col].fillna(df[col].mean(),inplace=True)\n",
        "  #df[col].fillna(df[col].mode(),inplace=True)\n",
        "  df[col].fillna(df[col].median(),inplace=True)\n",
        "\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "  le = LabelEncoder()\n",
        "  df[col] = le.fit_transform(df[col])\n",
        "\n",
        "\n",
        "features=['Temperature_day','Temperature_night','AirPressure_hPa','WindSpeed_km/h','Precipitation_mm','Wind_direction']\n",
        "X=df[features]\n",
        "y=df['Outlook']\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "rf=RandomForestClassifier(n_estimators=100,random_state=1)\n",
        "rf.fit(X_train,y_train)\n",
        "predictions=rf.predict(X_valid)\n",
        "\n",
        "print(f\"Accuracy score: {accuracy_score(y_valid,predictions)}\")\n",
        "print(f\"Precison score: {precision_score(y_valid,predictions, average='weighted')}\")\n",
        "print(f\"Recall score: {recall_score(y_valid,predictions,average='weighted')}\")\n",
        "print(f\"F1 score: {f1_score(y_valid,predictions,average='weighted')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import zipfile\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "with zipfile.ZipFile('/content/archive (4).zip') as z:\n",
        "  with z.open('weather_dirty.csv') as f:\n",
        "    df = pd.read_csv(f , sep=';')\n",
        "\n",
        "df = df.dropna(axis=1, how='all')\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "  le = LabelEncoder()\n",
        "  df[col] = le.fit_transform(df[col])\n",
        "\n",
        "features = ['Temperature_day', 'Temperature_night', 'AirPressure_hPa', 'WindSpeed_km/h', 'Precipitation_mm','Wind_direction']\n",
        "\n",
        "X=df[features]\n",
        "y=df['Outlook']\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "def impute_with_extension(X_train, X_valid):\n",
        "    cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
        "    X_train_plus = X_train.copy()\n",
        "    X_valid_plus = X_valid.copy()\n",
        "\n",
        "    for col in cols_with_missing:\n",
        "        X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
        "        X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
        "\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train_plus), columns=X_train_plus.columns)\n",
        "    imputed_X_valid = pd.DataFrame(imputer.transform(X_valid_plus), columns=X_valid_plus.columns)\n",
        "\n",
        "    return imputed_X_train, imputed_X_valid\n",
        "\n",
        "imputed_X_train, imputed_X_valid = impute_with_extension(X_train, X_valid)\n",
        "rf=RandomForestClassifier(n_estimators=100,random_state=1)\n",
        "rf.fit(imputed_X_train,y_train)\n",
        "predictions=rf.predict(imputed_X_valid)\n",
        "\n",
        "print(f\"Accuracy score: {accuracy_score(y_valid,predictions):4f}\")\n",
        "print(f\"Precison score: {precision_score(y_valid,predictions, average='weighted'):.4f}\")\n",
        "print(f\"Recall score: {recall_score(y_valid,predictions,average='weighted'):.4f}\")\n",
        "print(f\"F1 score: {f1_score(y_valid,predictions,average='weighted'):.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r1JksDb13PD",
        "outputId": "1907ff34-8df8-41f8-c24e-918e939546e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.779221\n",
            "Precison score: 0.7713\n",
            "Recall score: 0.7792\n",
            "F1 score: 0.7665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}